{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e207d5-2211-46d9-97a4-28c6bc3cf7d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T01:34:39.490365Z",
     "start_time": "2024-12-30T01:34:39.475513Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e2c7fb5bb1abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytensor\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "from pytensor_ml.activations import LeakyReLU\n",
    "from pytensor_ml.layers import Linear, Sequential\n",
    "from pytensor_ml.loss import CrossEntropy\n",
    "from pytensor_ml.model import Model\n",
    "from pytensor_ml.optimizers import ADAGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765364c1382d18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "y_onehot = OneHotEncoder().fit_transform(y[:, None]).toarray()\n",
    "X_normed = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5af7790f72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_in = Input('X_in', shape=(64, ))\n",
    "X_in = pytensor.tensor.tensor(\"X_in\", shape=(None, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de28447c610681",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_network = Sequential(\n",
    "    Linear(\"Linear_1\", n_in=64, n_out=256),\n",
    "    LeakyReLU(),\n",
    "    Linear(\"Linear_2\", n_in=256, n_out=128),\n",
    "    LeakyReLU(),\n",
    "    Linear(\"Logits\", n_in=128, n_out=10),\n",
    ")\n",
    "\n",
    "y_hat = prediction_network(X_in)\n",
    "model = Model(X_in, y_hat)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a13ab85dfff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CrossEntropy(expect_onehot_labels=True, expect_logits=True, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c942c50f9fafa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = SGD(model, loss_fn, ndim_out=2, learning_rate=1e-3)\n",
    "optim = ADAGrad(model, loss_fn, ndim_out=2, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f94af471f5fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.initalize_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db544810345190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "n_obs = X.shape[0]\n",
    "cutpoints = np.arange(0, n_obs, 1000).tolist()\n",
    "cutpoints += [n_obs]\n",
    "batch_slices = list(itertools.pairwise(cutpoints))\n",
    "loss_history = []\n",
    "n_epochs = 1000\n",
    "\n",
    "for _ in tqdm(range(n_epochs)):\n",
    "    all_idx = np.arange(n_obs)\n",
    "    np.random.shuffle(all_idx)\n",
    "    y_epoch = y_onehot[all_idx, :]\n",
    "    X_epoch = X_normed[all_idx, :]\n",
    "    for start, stop in batch_slices:\n",
    "        idx = slice(start, stop)\n",
    "        loss = optim.step(X_epoch[idx], y_epoch[idx])\n",
    "        loss_history.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5dfb676391f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce262edfd2417b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "y_hat_logits = model.predict(X_normed)\n",
    "y_hat_probs = softmax(y_hat_logits, axis=-1)\n",
    "y_hat = np.argmax(y_hat_probs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874811b4763620c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sns.heatmap(confusion_matrix(y, y_hat), annot=True, fmt=\"0.0f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49082db0d9c7093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
